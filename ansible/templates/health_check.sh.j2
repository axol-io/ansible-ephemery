#!/bin/bash
#
# Ephemery Health Check Script
# Generated by Ansible
#
# This script checks the health of Ephemery nodes and performs failover if needed
#

# Configuration
NODES=({% for node in backend_nodes %}"{{ node }}"{% if not loop.last %} {% endif %}{% endfor %})
NODE_IPS=({% for node in backend_nodes %}"{{ hostvars[node].ansible_host }}"{% if not loop.last %} {% endif %}{% endfor %})
PRIMARY_NODE="{{ backend_nodes | selectattr('node_role', 'equalto', 'primary') | first | default(backend_nodes[0]) }}"
LB_TYPE="{{ lb_type }}"
LOG_FILE="/var/log/ephemery_health_check.log"
SLACK_WEBHOOK="{{ slack_webhook | default('') }}"
NOTIFY_FAILURE="{{ notify_failure | default('true') }}"
PERFORM_FAILOVER="{{ automatic_failover | default('true') }}"
MAX_FAILURES=3
HEALTHCHECK_TIMEOUT=5

# Log with timestamp
log() {
    echo "$(date +'%Y-%m-%d %H:%M:%S') - $1" | tee -a $LOG_FILE
}

log "Starting Ephemery health check"

# Check if a node is healthy
check_node_health() {
    local node_ip=$1
    local node_name=$2
    local failures=0
    
    # Check execution client (HTTP RPC)
    if ! curl -s -m $HEALTHCHECK_TIMEOUT -o /dev/null -w "%{http_code}" http://${node_ip}:8545/health | grep -q "200"; then
        log "WARN: ${node_name} execution client HTTP RPC health check failed"
        ((failures++))
    fi
    
    # Check execution client (WebSocket)
    if ! nc -z -w $HEALTHCHECK_TIMEOUT ${node_ip} 8546 > /dev/null 2>&1; then
        log "WARN: ${node_name} execution client WebSocket health check failed"
        ((failures++))
    fi
    
    # Check consensus client
    if ! curl -s -m $HEALTHCHECK_TIMEOUT -o /dev/null -w "%{http_code}" http://${node_ip}:5052/eth/v1/node/health | grep -q "200"; then
        log "WARN: ${node_name} consensus client health check failed"
        ((failures++))
    fi
    
    # Return 0 if healthy, 1 if unhealthy
    [ $failures -lt $MAX_FAILURES ]
    return $?
}

# Update load balancer configuration
update_load_balancer() {
    local action=$1  # "enable" or "disable"
    local node_name=$2
    local node_ip=$3
    
    log "Updating load balancer: ${action} node ${node_name}"
    
    if [ "$LB_TYPE" == "nginx" ]; then
        # Update NGINX upstream configuration
        # This is a simplified example and might need more complex logic
        # in a real-world scenario
        sed -i "s/server ${node_ip}:8545/server ${node_ip}:8545 ${action == 'disable' ? 'down' : ''}/g" /etc/nginx/conf.d/ephemery_lb.conf
        systemctl reload nginx
    elif [ "$LB_TYPE" == "haproxy" ]; then
        # Use HAProxy socket commands to enable/disable servers
        if [ "$action" == "disable" ]; then
            echo "disable server ephemery_execution_backend/${node_name}" | socat /run/haproxy/admin.sock -
            echo "disable server ephemery_execution_ws_backend/${node_name}" | socat /run/haproxy/admin.sock -
            echo "disable server ephemery_consensus_backend/${node_name}" | socat /run/haproxy/admin.sock -
        else
            echo "enable server ephemery_execution_backend/${node_name}" | socat /run/haproxy/admin.sock -
            echo "enable server ephemery_execution_ws_backend/${node_name}" | socat /run/haproxy/admin.sock -
            echo "enable server ephemery_consensus_backend/${node_name}" | socat /run/haproxy/admin.sock -
        fi
    fi
}

# Perform failover
perform_failover() {
    local failed_node=$1
    local failed_node_ip=$2
    local new_primary=""
    
    log "ALERT: Primary node ${failed_node} is unhealthy, initiating failover"
    
    # Find a healthy backup node
    for i in "${!NODES[@]}"; do
        if [ "${NODES[$i]}" != "$failed_node" ]; then
            if check_node_health "${NODE_IPS[$i]}" "${NODES[$i]}"; then
                new_primary="${NODES[$i]}"
                break
            fi
        fi
    done
    
    if [ -z "$new_primary" ]; then
        log "ERROR: No healthy backup nodes available for failover"
        notify "CRITICAL: Ephemery cluster has no healthy nodes available for failover"
        return 1
    fi
    
    # Update load balancer configuration
    update_load_balancer "disable" "$failed_node" "$failed_node_ip"
    
    log "SUCCESS: Failover completed, new primary node is ${new_primary}"
    notify "Ephemery cluster failover completed. New primary: ${new_primary}, failed node: ${failed_node}"
    
    return 0
}

# Send notifications
notify() {
    local message=$1
    
    if [ "$NOTIFY_FAILURE" == "true" ] && [ ! -z "$SLACK_WEBHOOK" ]; then
        curl -s -X POST -H 'Content-type: application/json' --data "{\"text\":\"${message}\"}" $SLACK_WEBHOOK
    fi
    
    log "NOTIFICATION: $message"
}

# Main health check loop
all_healthy=true

# Check all nodes
for i in "${!NODES[@]}"; do
    node_name="${NODES[$i]}"
    node_ip="${NODE_IPS[$i]}"
    
    if check_node_health "$node_ip" "$node_name"; then
        log "Node ${node_name} is healthy"
    else
        log "ERROR: Node ${node_name} is unhealthy"
        all_healthy=false
        
        # If this is the primary node and failover is enabled
        if [ "$node_name" == "$PRIMARY_NODE" ] && [ "$PERFORM_FAILOVER" == "true" ]; then
            perform_failover "$node_name" "$node_ip"
        else
            # For non-primary nodes, just update the load balancer
            update_load_balancer "disable" "$node_name" "$node_ip"
            notify "WARNING: Ephemery node ${node_name} is unhealthy and has been removed from the load balancer"
        fi
    fi
done

if $all_healthy; then
    log "All nodes are healthy"
fi

log "Health check completed"
exit 0 